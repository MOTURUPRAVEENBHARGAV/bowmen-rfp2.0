[2025-07-14 11:08:40] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_999264581dcfaeafaee93ea8392e56c9
[2025-07-14 11:08:40] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Risk Assessment Consistency:

i. Enforce uniform t...'. Received session_has_document flag: False
[2025-07-14 11:08:45] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Enforce uniform terminology in OpenPages risk assessments", "top_k": 5}
[2025-07-14 11:08:49] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Standardize assessment methods in OpenPages", "top_k": 5}
[2025-07-14 11:08:53] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Implement consistent rating scales in OpenPages", "top_k": 5}
[2025-07-14 11:09:09] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 11:09:45] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_999264581dcfaeafaee93ea8392e56c9
[2025-07-14 11:09:45] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is ibm openpages?...'. Received session_has_document flag: False
[2025-07-14 11:09:47] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "what is IBM OpenPages?", "top_k": 5}
[2025-07-14 11:09:55] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 11:16:05] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 11:16:05] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is ibm openpages?...'. Received session_has_document flag: False
[2025-07-14 11:16:07] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "what is IBM OpenPages?", "top_k": 5}
[2025-07-14 11:16:13] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 11:16:13] [ERROR] [agent_logger.answering_agent:54] - Error generating final answer: 'Input to ChatPromptTemplate is missing variables {\'\\n  "final_answer"\'}.  Expected: [\'\\n  "final_answer"\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n  "final_answer"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n  "final_answer"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\answering_agent.py", line 44, in make_final_answer
    response_dict = await chain.ainvoke({"query": query, "evidence": evidence, "context": context_str})
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n  "final_answer"\'}.  Expected: [\'\\n  "final_answer"\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n  "final_answer"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n  "final_answer"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:33:56] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 11:33:56] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is ibm openpages?...'. Received session_has_document flag: False
[2025-07-14 11:33:59] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "what is IBM OpenPages?", "top_k": 5}
[2025-07-14 11:34:07] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 11:50:41] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 11:50:41] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is ibm openpages?...'. Received session_has_document flag: False
[2025-07-14 11:50:43] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "what is IBM OpenPages?", "top_k": 5}
[2025-07-14 11:50:51] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 11:59:13] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 11:59:13] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is ibm openpages?...'. Received session_has_document flag: False
[2025-07-14 11:59:14] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "what is IBM OpenPages?", "top_k": 5}
[2025-07-14 11:59:17] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:17] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:17] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:17] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:17] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:18] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:19] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the causes and solutions for internal errors during final evidence analysis in IBM OpenPages?", "top_k": 5}
[2025-07-14 11:59:23] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:24] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 11:59:25] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 12:34:19] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 12:34:19] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is ibm openpages?...'. Received session_has_document flag: False
[2025-07-14 12:34:21] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "what is IBM OpenPages?", "top_k": 5}
[2025-07-14 12:34:23] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:23] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:23] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:24] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:24] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:25] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:26] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the causes and solutions for internal errors during final evidence analysis in IBM OpenPages?", "top_k": 5}
[2025-07-14 12:34:29] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:30] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:34:31] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 12:37:19] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 12:37:19] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Risk Assessment Consistency:

i. Enforce uniform t...'. Received session_has_document flag: False
[2025-07-14 12:37:23] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Enforce uniform risk terminology in OpenPages", "top_k": 5}
[2025-07-14 12:37:27] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Implement consistent risk assessment methods in OpenPages", "top_k": 5}
[2025-07-14 12:37:30] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:30] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:31] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Establish standardized risk rating scales in OpenPages", "top_k": 5}
[2025-07-14 12:37:33] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:33] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:35] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:37] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:39] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 12:37:41] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 13:19:01] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_a621016c54fccfde4469551cf4a2878c
[2025-07-14 13:19:01] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Risk Assessment Consistency:

i. Enforce uniform t...'. Received session_has_document flag: False
[2025-07-14 13:19:08] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Enforce uniform risk terminology in OpenPages", "top_k": 5}
[2025-07-14 13:19:12] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Implement consistent risk assessment methods in OpenPages", "top_k": 5}
[2025-07-14 13:19:14] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 13:19:16] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Establish standardized risk rating scales in OpenPages", "top_k": 5}
[2025-07-14 13:19:18] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 13:19:18] [ERROR] [agent_logger.evidence_agent:52] - Quick filter agent failed: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 45, in run_quick_relevance_check
    result = await chain.ainvoke({"query": query, "evidence": evidence or "No evidence provided","context": context_str})
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'"is_relevant"\'}.  Expected: [\'"is_relevant"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {"is_relevant"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{"is_relevant"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 13:19:19] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 13:19:22] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 13:19:24] [ERROR] [agent_logger.evidence_agent:85] - Gap analysis agent failed: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\evidencer.py", line 80, in run_gap_analysis
    result_content = await chain.ainvoke({"query": query, "evidence": combined_evidence, "context": context_str})
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n      "Sufficient"\'}.  Expected: [\'\\n      "Sufficient"\', \'context\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n      "Sufficient"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n      "Sufficient"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 13:19:26] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 13:58:41] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_dc188501ce9c528a7594e913059cdfba
[2025-07-14 13:58:41] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Link the findings issues to working papers used fo...'. Received session_has_document flag: False
[2025-07-14 14:02:06] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_dc188501ce9c528a7594e913059cdfba
[2025-07-14 14:02:06] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Link the findings issues to working papers used fo...'. Received session_has_document flag: False
[2025-07-14 14:05:43] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_dc188501ce9c528a7594e913059cdfba
[2025-07-14 14:05:43] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Link the findings issues to working papers used fo...'. Received session_has_document flag: False
[2025-07-14 14:10:33] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_dc188501ce9c528a7594e913059cdfba
[2025-07-14 14:10:33] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Link the findings issues to working papers used fo...'. Received session_has_document flag: False
[2025-07-14 14:10:35] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How can I link findings and issues to working papers in IBM OpenPages?", "top_k": 5}
[2025-07-14 14:10:54] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Identify the specific working papers referenced in the testing process for the issues and findings discussed.", "top_k": 5}
[2025-07-14 14:11:10] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the detailed process of linking specific findings to their corresponding working papers?", "top_k": 5}
[2025-07-14 14:11:26] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Identify specific working papers used for testing in relation to issue and finding management processes in IBM OpenPages", "top_k": 5}
[2025-07-14 14:11:40] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:22:55] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_928f00ba586c32ab8f66bce31155e884
[2025-07-14 15:22:55] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Link the findings issues to working papers used fo...'. Received session_has_document flag: False
[2025-07-14 15:22:57] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How can I link findings and issues to working papers in IBM OpenPages?", "top_k": 5}
[2025-07-14 15:23:13] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Identify specific working papers used for testing that correspond to the logged audit findings and corrective action plans", "top_k": 5}
[2025-07-14 15:23:20] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Identify the specific working papers used for testing that correspond to the documented issues and corrective action plans", "top_k": 5}
[2025-07-14 15:23:25] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How are working papers specifically utilized in the processes of search functionality, control testing, issue management, and corrective action plans?", "top_k": 5}
[2025-07-14 15:23:28] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:23:28] [ERROR] [agent_logger.answering_agent:54] - Error generating final answer: 'Input to ChatPromptTemplate is missing variables {\'\\n  "final_answer"\'}.  Expected: [\'\\n  "final_answer"\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n  "final_answer"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n  "final_answer"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
Traceback (most recent call last):
  File "c:\Users\HarshaVardhan\OneDrive - Bowmen Group Ltd\Desktop\Agents\RFP Agent CE\Agents\answering_agent.py", line 44, in make_final_answer
    response_dict = await chain.ainvoke({"query": query, "evidence": evidence, "context": context_str})
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 3075, in ainvoke
    input = await coro_with_context(part(), context, create_task=True)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\runnables\base.py", line 1981, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    _inner_input = self._validate_input(inner_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HarshaVardhan\.conda\envs\bowmen_agent\Lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: 'Input to ChatPromptTemplate is missing variables {\'\\n  "final_answer"\'}.  Expected: [\'\\n  "final_answer"\', \'evidence\', \'query\'] Received: [\'query\', \'evidence\', \'context\']\nNote: if you intended {\n  "final_answer"} to be part of the string and not a variable, please escape it with double curly braces like: \'{{\n  "final_answer"}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
[2025-07-14 15:24:38] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_928f00ba586c32ab8f66bce31155e884
[2025-07-14 15:24:38] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Link the findings issues to working papers used fo...'. Received session_has_document flag: False
[2025-07-14 15:24:40] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How can I link findings and issues to working papers in IBM OpenPages?", "top_k": 5}
[2025-07-14 15:24:57] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Identify specific working papers used for testing that correspond to the registered findings and controls assessed", "top_k": 5}
[2025-07-14 15:25:02] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the specific process for linking findings issues to working papers used for testing in the GRC Solution?", "top_k": 5}
[2025-07-14 15:25:09] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How are working papers specifically utilized in the testing process for linking findings and issues in IBM OpenPages?", "top_k": 5}
[2025-07-14 15:25:29] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:25:54] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_c337cabf1f588dc4762ca18285f37a68
[2025-07-14 15:25:54] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool support dutch language?...'. Received session_has_document flag: False
[2025-07-14 15:25:55] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages support the Dutch language?", "top_k": 5}
[2025-07-14 15:26:05] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool offer Dutch language support for both functional and technical aspects, including chatbot assistance and on-site or remote implementation support by The Bowmen Group?", "top_k": 5}
[2025-07-14 15:26:12] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM Watson Assistant support Dutch language?", "top_k": 5}
[2025-07-14 15:26:20] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:27:57] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_c337cabf1f588dc4762ca18285f37a68
[2025-07-14 15:27:57] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Real-Time Reporting and User-Specific Control Pane...'. Received session_has_document flag: False
[2025-07-14 15:27:59] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Generate real-time reports and user-specific control panels in IBM OpenPages GRC to provide visibility on the status of assessment works and the overall compliance profile of the organization.", "top_k": 5}
[2025-07-14 15:28:04] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:36:44] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_34c646205d6a009899382d567cd12ac7
[2025-07-14 15:36:44] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Action Plan Creation and Management: Support the c...'. Received session_has_document flag: False
[2025-07-14 15:36:47] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How does IBM OpenPages support the creation and management of action plans for mitigating findings and documenting actions taken?", "top_k": 5}
[2025-07-14 15:37:07] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How to create an Action Plan in OpenPages?", "top_k": 5}
[2025-07-14 15:37:22] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the steps to manage Action Plans in OpenPages?", "top_k": 5}
[2025-07-14 15:37:36] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How to monitor tasks within an Action Plan in OpenPages?", "top_k": 5}
[2025-07-14 15:38:18] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_34c646205d6a009899382d567cd12ac7
[2025-07-14 15:38:18] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Action Plan Creation and Management: Support the c...'. Received session_has_document flag: False
[2025-07-14 15:38:19] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How does IBM OpenPages support the creation and management of action plans for mitigating findings and documenting actions taken?", "top_k": 5}
[2025-07-14 15:38:38] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How to create an Action Plan in OpenPages?", "top_k": 5}
[2025-07-14 15:38:52] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the steps to manage Action Plans in OpenPages?", "top_k": 5}
[2025-07-14 15:39:06] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How to monitor tasks within an Action Plan in OpenPages?", "top_k": 5}
[2025-07-14 15:39:32] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:42:09] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_c71339900c3dc4fd91629569570cc7e6
[2025-07-14 15:42:09] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Action Plan Creation and Management: Support the c...'. Received session_has_document flag: False
[2025-07-14 15:42:11] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How does IBM OpenPages support the creation and management of action plans for mitigating findings and documenting actions taken?", "top_k": 5}
[2025-07-14 15:42:31] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How to create an Action Plan in OpenPages?", "top_k": 5}
[2025-07-14 15:42:46] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the steps to manage Action Plans in OpenPages?", "top_k": 5}
[2025-07-14 15:43:01] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How to monitor tasks within an Action Plan in OpenPages?", "top_k": 5}
[2025-07-14 15:43:28] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:47:29] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_fee90fb30d4dcdcdd34a67a6a79a42b5
[2025-07-14 15:47:30] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'what is the latest version of ibm openapges?...'. Received session_has_document flag: False
[2025-07-14 15:47:31] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the latest version of IBM OpenPages?", "top_k": 5}
[2025-07-14 15:47:42] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 15:58:09] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_fee90fb30d4dcdcdd34a67a6a79a42b5
[2025-07-14 15:58:09] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool support Dutch?...'. Received session_has_document flag: False
[2025-07-14 15:58:11] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages support Dutch?", "top_k": 5}
[2025-07-14 15:58:19] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool's functional support from The Bowmen Group include on-site assistance for Dutch language users?", "top_k": 5}
[2025-07-14 15:58:26] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool offer Dutch language support?", "top_k": 5}
[2025-07-14 15:58:34] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does Bowmen Group offer Dutch language support for on-site assistance?", "top_k": 5}
[2025-07-14 15:58:43] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_fee90fb30d4dcdcdd34a67a6a79a42b5
[2025-07-14 15:58:44] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool support Dutch?...'. Received session_has_document flag: False
[2025-07-14 15:58:45] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages support Dutch?", "top_k": 5}
[2025-07-14 15:58:53] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool's functional support from The Bowmen Group include on-site assistance for Dutch language users?", "top_k": 5}
[2025-07-14 15:59:00] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool offer Dutch language support?", "top_k": 5}
[2025-07-14 15:59:07] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does Bowmen Group offer Dutch language support for on-site assistance?", "top_k": 5}
[2025-07-14 16:00:24] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_fee90fb30d4dcdcdd34a67a6a79a42b5
[2025-07-14 16:00:24] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool support Dutch?...'. Received session_has_document flag: False
[2025-07-14 16:00:25] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages support Dutch?", "top_k": 5}
[2025-07-14 16:00:37] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool's functional support from The Bowmen Group include on-site assistance for Dutch language users?", "top_k": 5}
[2025-07-14 16:00:44] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool offer Dutch language support?", "top_k": 5}
[2025-07-14 16:00:52] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does Bowmen Group offer Dutch language support for on-site assistance?", "top_k": 5}
[2025-07-14 16:00:56] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 16:45:43] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 16:45:44] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'hello...'. Received session_has_document flag: False
[2025-07-14 16:50:58] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 16:50:58] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool help in logging?...'. Received session_has_document flag: False
[2025-07-14 16:51:00] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages GRC assist with logging?", "top_k": 5}
[2025-07-14 16:51:13] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool support logging for 'People, Process (IT/Technology), Partners (Third parties), and Premises' loss prevention?", "top_k": 5}
[2025-07-14 16:51:20] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool facilitate logging of Internal Audit FRC observations against controls?", "top_k": 5}
[2025-07-14 16:51:27] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool facilitate logging of observations from Internal Audit FRC against controls?", "top_k": 5}
[2025-07-14 16:51:31] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 16:54:21] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 16:54:21] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Contract updating schedule...'. Received session_has_document flag: False
[2025-07-14 16:54:23] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the contract updating schedule in IBM OpenPages?", "top_k": 5}
[2025-07-14 16:54:30] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Contract updating schedule and methods for documenting progress, including both qualitative and quantitative measures", "top_k": 5}
[2025-07-14 16:54:35] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Contractual obligations for regular, automated software updates and their specified schedule", "top_k": 5}
[2025-07-14 16:54:52] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific contractual commitments for regular software update schedules", "top_k": 5}
[2025-07-14 16:54:56] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 16:55:21] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 16:55:21] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 16:55:22] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 16:55:28] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 16:55:32] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 16:55:40] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 16:55:42] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 16:58:51] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 16:58:51] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'hello...'. Received session_has_document flag: False
[2025-07-14 16:59:08] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 16:59:08] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 16:59:09] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 16:59:15] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 16:59:19] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 16:59:27] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 16:59:28] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:01:12] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 17:01:12] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:01:14] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:01:21] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:01:25] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:01:33] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:01:34] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:03:07] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 17:03:07] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:03:08] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:03:15] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:03:20] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:03:28] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:03:29] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:09:12] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 17:09:12] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:09:15] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:09:24] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:09:28] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:09:42] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:09:44] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:12:03] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_fee90fb30d4dcdcdd34a67a6a79a42b5
[2025-07-14 17:12:03] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool support Dutch?...'. Received session_has_document flag: False
[2025-07-14 17:12:05] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages support Dutch?", "top_k": 5}
[2025-07-14 17:12:15] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool's functional support from The Bowmen Group include on-site assistance for Dutch language users?", "top_k": 5}
[2025-07-14 17:12:23] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool offer Dutch language support?", "top_k": 5}
[2025-07-14 17:12:32] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does Bowmen Group offer Dutch language support for on-site assistance?", "top_k": 5}
[2025-07-14 17:12:36] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:13:19] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_fee90fb30d4dcdcdd34a67a6a79a42b5
[2025-07-14 17:13:19] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'does the tool support Dutch?...'. Received session_has_document flag: False
[2025-07-14 17:13:21] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does IBM OpenPages support Dutch?", "top_k": 5}
[2025-07-14 17:13:28] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool's functional support from The Bowmen Group include on-site assistance for Dutch language users?", "top_k": 5}
[2025-07-14 17:13:35] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does the tool offer Dutch language support?", "top_k": 5}
[2025-07-14 17:13:42] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Does Bowmen Group offer Dutch language support for on-site assistance?", "top_k": 5}
[2025-07-14 17:13:47] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:14:25] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_5d90dcfd617ed49941ef5100f88cef04
[2025-07-14 17:14:25] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:14:27] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:14:40] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:14:45] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:14:53] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:14:54] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:18:00] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:18:00] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'third parties SLA...'. Received session_has_document flag: False
[2025-07-14 17:18:02] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party service level agreements in IBM OpenPages GRC?", "top_k": 5}
[2025-07-14 17:18:07] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs)", "top_k": 5}
[2025-07-14 17:18:11] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party specific Service Level Agreements (SLAs)", "top_k": 5}
[2025-07-14 17:18:16] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:18:35] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:18:35] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Contract updating schedule...'. Received session_has_document flag: False
[2025-07-14 17:18:36] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the contract updating schedule in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:18:44] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Contract updating schedule and methods for documenting progress, including both qualitative and quantitative measures", "top_k": 5}
[2025-07-14 17:18:50] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Contractual obligations for regular, automated software updates and their specified schedule", "top_k": 5}
[2025-07-14 17:19:08] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific contractual commitments for regular software update schedules", "top_k": 5}
[2025-07-14 17:19:12] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:20:05] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:20:05] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'how many languages are offered asfor ibm oepnapege...'. Received session_has_document flag: False
[2025-07-14 17:20:07] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How many languages are supported by IBM OpenPages?", "top_k": 5}
[2025-07-14 17:20:14] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the exact number of languages supported by IBM OpenPages out-of-the-box?", "top_k": 5}
[2025-07-14 17:20:21] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the total number of languages supported by IBM OpenPages?", "top_k": 5}
[2025-07-14 17:20:29] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the total number of languages supported in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:20:35] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:22:08] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:22:08] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:22:09] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:22:10] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20are%20the%20details%20regarding%20third-party%20SLAs%20in%20IBM%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:22:16] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:22:16] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Third-party%20Service%20Level%20Agreements%20(SLAs)%20details&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:22:20] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:22:20] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20service%20level%20agreements&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:22:27] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:22:29] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:24:30] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:24:30] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-party mapping: linked to process map (which ...'. Received session_has_document flag: False
[2025-07-14 17:24:31] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "How are third-parties mapped to processes in IBM OpenPages, including their descriptions, levels of dependency, and where contract repositories are stored?", "top_k": 5}
[2025-07-14 17:24:38] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Which third-party vendors are linked to specific processes in OpenPages?", "top_k": 5}
[2025-07-14 17:24:42] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the description of each third-party vendor in OpenPages?", "top_k": 5}
[2025-07-14 17:24:42] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20is%20the%20description%20of%20each%20third-party%20vendor%20in%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:24:44] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What is the level of dependency for each third-party vendor in OpenPages?", "top_k": 5}
[2025-07-14 17:24:44] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20is%20the%20level%20of%20dependency%20for%20each%20third-party%20vendor%20in%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:24:54] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:28:35] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:28:35] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:28:37] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:28:37] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20are%20the%20details%20regarding%20third-party%20SLAs%20in%20IBM%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:28:43] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:28:43] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Third-party%20Service%20Level%20Agreements%20(SLAs)%20details&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:28:48] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:28:48] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20service%20level%20agreements&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:28:56] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:28:56] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20SLAs&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:28:57] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:31:52] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:31:52] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:31:56] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:31:57] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20are%20the%20details%20regarding%20third-party%20SLAs%20in%20IBM%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:32:03] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:32:07] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:32:07] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20service%20level%20agreements&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:32:15] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:32:17] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:38:45] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:38:45] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:38:47] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:38:47] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20are%20the%20details%20regarding%20third-party%20SLAs%20in%20IBM%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:38:54] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:38:54] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Third-party%20Service%20Level%20Agreements%20(SLAs)%20details&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:38:57] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:38:58] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20service%20level%20agreements&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:39:06] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:39:06] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20SLAs&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:39:07] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:39:50] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:39:50] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:39:52] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:39:52] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20are%20the%20details%20regarding%20third-party%20SLAs%20in%20IBM%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:39:59] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:39:59] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Third-party%20Service%20Level%20Agreements%20(SLAs)%20details&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:40:03] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:40:03] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20service%20level%20agreements&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:40:11] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:40:11] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20SLAs&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:40:13] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
[2025-07-14 17:42:06] [INFO] [agent_logger.bowmen_agent_pipeline:38] - Initializing GRCPipeline for collection: rfp_chat_ef980e845568d4018e4c493c3ff4a38e
[2025-07-14 17:42:06] [INFO] [agent_logger.bowmen_agent_pipeline:112] - GRCPipeline run started. Question: 'Third-parties SLAs...'. Received session_has_document flag: False
[2025-07-14 17:42:08] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "What are the details regarding third-party SLAs in IBM OpenPages?", "top_k": 5}
[2025-07-14 17:42:08] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=What%20are%20the%20details%20regarding%20third-party%20SLAs%20in%20IBM%20OpenPages?&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:42:14] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Third-party Service Level Agreements (SLAs) details", "top_k": 5}
[2025-07-14 17:42:14] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Third-party%20Service%20Level%20Agreements%20(SLAs)%20details&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:42:18] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party service level agreements", "top_k": 5}
[2025-07-14 17:42:18] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20service%20level%20agreements&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:42:27] [INFO] [agent_logger.tools_agent:73] - Sending payload to VectorDB: {"collection_name": "rfp_spreadsheet_collection_v1", "question": "Specific details of third-party SLAs", "top_k": 5}
[2025-07-14 17:42:27] [WARNING] [agent_logger.tools_agent:132] - An unexpected error occurred during Google search: Client error '429 Too Many Requests' for url 'https://www.googleapis.com/customsearch/v1?q=Specific%20details%20of%20third-party%20SLAs&key=AIzaSyAg9TlYm8EYDnlp6ZdOtKu0ffipZVXVMaM&cx=00162c3db1cac4da4'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
[2025-07-14 17:42:29] [INFO] [agent_logger.answering_agent:32] - Generating final answer for query.
